{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "train = pd.read_csv('training_dataset.csv')\n",
    "test = pd.read_csv('validation_set.csv')\n",
    "\n",
    "train = train.drop(columns=['customer_number'])\n",
    "test = test.drop(columns=['customer_number'])\n",
    "\n",
    "target = 'berlangganan_deposito'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all object columns\n",
    "obj_columns = train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Loop through each object column and display unique values and their counts\n",
    "for col in obj_columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(train[col].value_counts())\n",
    "    print(f\"Total unique values: {train[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, test_size=0.2, random_state=42, stratify=train[target])\n",
    "\n",
    "X_train = train.drop(columns=[target])\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=[target])\n",
    "y_val = val[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode for lgbm and xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X_train_le = X_train.copy()\n",
    "X_val_le = X_val.copy()\n",
    "\n",
    "for col in obj_columns:\n",
    "    X_train_le[col] = le.fit_transform(X_train[col])\n",
    "    X_val_le[col] = le.transform(X_val[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctb = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    cat_features=obj_columns.tolist(),\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    task_type='GPU',  # Use GPU for training\n",
    "    devices='0'  # Adjust based on your GPU setup\n",
    ")\n",
    "\n",
    "lgb = LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    device = 'gpu',\n",
    "    gpu_platform_id=0,  # Adjust based on your GPU setup\n",
    "    gpu_device_id=0  # Adjust based on your GPU setup\n",
    ")\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    tree_method='hist',  # Use GPU for training\n",
    "    device='cuda',\n",
    "    eval_metric='auc',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctb.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_set=(X_val, y_val), \n",
    "    early_stopping_rounds=100,\n",
    "    verbose=100,\n",
    ")\n",
    "\n",
    "lgb.fit(\n",
    "    X_train_le,\n",
    "    y_train,\n",
    "    eval_set=(X_val_le, y_val),\n",
    "    categorical_feature=obj_columns.tolist(),\n",
    "    eval_metric='auc',\n",
    ")\n",
    "\n",
    "xgb.fit(\n",
    "    X_train_le,\n",
    "    y_train,\n",
    "    eval_set=[(X_val_le, y_val)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 1 plot with 3 lines for each model\n",
    "def plot_roc_curves(models, X_val, X_val_le, y_val):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for model in models:\n",
    "        if model == ctb:\n",
    "            y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            y_proba = model.predict_proba(X_val_le)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "        roc_auc = roc_auc_score(y_val, y_proba)\n",
    "        plt.plot(fpr, tpr, label=f'{model.__class__.__name__} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curves([ctb, lgb, xgb], X_val, X_val_le, y_val)\n",
    "\n",
    "def plot_precision_recall_curves(models, X_val, X_val_le, y_val):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for model in models:\n",
    "        if model == ctb:\n",
    "            y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            y_proba = model.predict_proba(X_val_le)[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(y_val, y_proba)\n",
    "        auc_pr = np.trapz(precision, recall)\n",
    "        plt.plot(recall, precision, label=f'{model.__class__.__name__} (AUC PR = {auc_pr:.2f})')\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curves')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_precision_recall_curves([ctb, lgb, xgb], X_val, X_val_le, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate class weights and scale_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classcount = y_train.value_counts()\n",
    "\n",
    "# calculate class weights for lgbm and catboost\n",
    "classweights = {0: classcount[1] / classcount[0], 1: 1.0}\n",
    "\n",
    "# calculate scale_pos_weight for xgboost\n",
    "scaleposweight = classcount[0] / classcount[1]\n",
    "\n",
    "print(f\"Class Weights: {classweights}\")\n",
    "print(f\"Scale Pos Weight: {scaleposweight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctb = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    cat_features=obj_columns.tolist(),\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    class_weights=classweights,\n",
    "    task_type='GPU',  # Use GPU for training\n",
    "    devices='0'  # Adjust based on your GPU setup\n",
    ")\n",
    "\n",
    "lgb = LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    class_weight=classweights,\n",
    "    device = 'gpu',\n",
    "    gpu_platform_id=0,  # Adjust based on your GPU setup\n",
    "    gpu_device_id=0  # Adjust based on your GPU setup\n",
    ")\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scaleposweight,\n",
    "    tree_method='hist',  # Use GPU for training\n",
    "    device='cuda',\n",
    "    eval_metric='auc',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctb.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_set=(X_val, y_val), \n",
    "    early_stopping_rounds=100,\n",
    "    verbose=100,\n",
    ")\n",
    "\n",
    "lgb.fit(\n",
    "    X_train_le,\n",
    "    y_train,\n",
    "    eval_set=(X_val_le, y_val),\n",
    "    categorical_feature=obj_columns.tolist(),\n",
    "    eval_metric='auc',\n",
    ")\n",
    "\n",
    "xgb.fit(\n",
    "    X_train_le,\n",
    "    y_train,\n",
    "    eval_set=[(X_val_le, y_val)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 1 plot with 3 lines for each model\n",
    "def plot_roc_curves(models, X_val, X_val_le, y_val):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for model in models:\n",
    "        if model == ctb:\n",
    "            y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            y_proba = model.predict_proba(X_val_le)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "        roc_auc = roc_auc_score(y_val, y_proba)\n",
    "        plt.plot(fpr, tpr, label=f'{model.__class__.__name__} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curves([ctb, lgb, xgb], X_val, X_val_le, y_val)\n",
    "\n",
    "def plot_precision_recall_curves(models, X_val, X_val_le, y_val):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for model in models:\n",
    "        if model == ctb:\n",
    "            y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            y_proba = model.predict_proba(X_val_le)[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(y_val, y_proba)\n",
    "        auc_pr = np.trapz(precision, recall)\n",
    "        plt.plot(recall, precision, label=f'{model.__class__.__name__} (AUC PR = {auc_pr:.2f})')\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curves')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_precision_recall_curves([ctb, lgb, xgb], X_val, X_val_le, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
